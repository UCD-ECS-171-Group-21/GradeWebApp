{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df4d57e6-7021-497d-a14b-1ffcc7115766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d1 = np.array([2, 1, 0, 2, 0, 1, 1, 1])\n",
    "d2 = np.array([2, 1, 1, 1, 1, 0, 1, 1])\n",
    "d3 = np.array([1, 0, 1, 1, 1, 0, 1, 1])\n",
    "d4 = np.array([0, 0, 1, 3, 1, 0, 0, 0])\n",
    "d5 = np.array([0, 1, 0, 2, 1, 1, 1, 1])\n",
    "d6 = np.array([3, 2, 1, 0, 0, 1, 2, 1])\n",
    "d7 = np.array([3, 2, 1, 0, 0, 1, 2, 1])\n",
    "\n",
    "data_points = np.array([d1, d2, d3, d4, d5, d6, d7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55f5e3b4-c6ab-4859-9085-71aad299fed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# determine which centroid each point is closer to using cosine similarity\n",
    "def cosine_similarity_distance(vector_a, vector_b):\n",
    "    sum_va_vb = np.sum(vector_a*vector_b)\n",
    "    #print(sum_d1_d2)\n",
    "    \n",
    "    norm_a = np.sqrt(np.sum(vector_a**2))\n",
    "    #print(norm_a)\n",
    "    \n",
    "    norm_b = np.sqrt(np.sum(vector_b**2))\n",
    "    #print(norm_b)\n",
    "    \n",
    "    similarity = sum_va_vb / (norm_a * norm_b)\n",
    "    #print(similarity)\n",
    "    \n",
    "    distance = 1 - similarity\n",
    "    #print(distance)\n",
    "    \n",
    "    return distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "759e3f2d-dbdf-474f-90f1-10825d51d773",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between d1 and d2: 0.1784161637422509\n",
      "Cosine Similarity between d6 and d2: 0.1514718625761431\n",
      "Cosine Similarity between d1 and d3: 0.2928932188134524\n",
      "Cosine Similarity between d6 and d3: 0.36099034957730625\n",
      "Cosine Similarity between d1 and d4: 0.4777670321329065\n",
      "Cosine Similarity between d6 and d4: 0.9325800137536758\n",
      "Cosine Similarity between d1 and d5: 0.23019964108049895\n",
      "Cosine Similarity between d6 and d5: 0.5527864045000421\n",
      "Cosine Similarity between d1 and d7: 0.2254033307585166\n",
      "Cosine Similarity between d6 and d7: 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# for k = 2 randomly pick 2 centroids \n",
    "# c1 = d1 and c2 = d6\n",
    "#determine for every point if closer to d1 centroid or d6 centroid\n",
    "print(\"Cosine Similarity between d1 and d2:\", cosine_similarity_distance(d1, d2))\n",
    "print(\"Cosine Similarity between d6 and d2:\", cosine_similarity_distance(d6, d2))\n",
    "\n",
    "print(\"Cosine Similarity between d1 and d3:\", cosine_similarity_distance(d1, d3))\n",
    "print(\"Cosine Similarity between d6 and d3:\", cosine_similarity_distance(d6, d3))\n",
    "\n",
    "print(\"Cosine Similarity between d1 and d4:\", cosine_similarity_distance(d1, d4))\n",
    "print(\"Cosine Similarity between d6 and d4:\", cosine_similarity_distance(d6, d4))\n",
    "\n",
    "print(\"Cosine Similarity between d1 and d5:\", cosine_similarity_distance(d1, d5))\n",
    "print(\"Cosine Similarity between d6 and d5:\", cosine_similarity_distance(d6, d5))\n",
    "\n",
    "print(\"Cosine Similarity between d1 and d7:\", cosine_similarity_distance(d1, d7))\n",
    "print(\"Cosine Similarity between d6 and d7:\", cosine_similarity_distance(d6, d7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb6ef572-dd30-4140-ac3a-72d138b166b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cluster by shortest distance\n",
    "cluster_1 = np.array([d1, d3, d4, d5])\n",
    "cluster_2 = np.array([d6, d2, d7])\n",
    "\n",
    "#recalculate centroids using mean\n",
    "cluster_centroid_1 = np.mean(cluster_1, axis=0)\n",
    "cluster_centroid_2 = np.mean(cluster_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b16965cc-3733-4023-96d6-cc233eaa3f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between c1 and d1: 0.12712843905603044\n",
      "Cosine Similarity between c2 and d1: 0.18906924114806578\n",
      "Cosine Similarity between c1 and d2: 0.19322068869928433\n",
      "Cosine Similarity between c2 and d2: 0.08475076650111868\n",
      "Cosine Similarity between c1 and d3: 0.1513315752084945\n",
      "Cosine Similarity between c2 and d3: 0.2701995508002383\n",
      "Cosine Similarity between c1 and d4: 0.17378582066762494\n",
      "Cosine Similarity between c2 and d4: 0.8203355491812291\n",
      "Cosine Similarity between c1 and d5: 0.0865858568943676\n",
      "Cosine Similarity between c2 and d5: 0.4892460815447508\n",
      "Cosine Similarity between c1 and d6: 0.4506497344264643\n",
      "Cosine Similarity between c2 and d6: 0.010196916085054686\n",
      "Cosine Similarity between c1 and d7: 0.4506497344264643\n",
      "Cosine Similarity between c2 and d7: 0.010196916085054686\n"
     ]
    }
   ],
   "source": [
    "#recalc clusters and determine convergence\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d1:\", cosine_similarity_distance(cluster_centroid_1, d1))\n",
    "print(\"Cosine Similarity between c2 and d1:\", cosine_similarity_distance(cluster_centroid_2, d1))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d2:\", cosine_similarity_distance(cluster_centroid_1, d2))\n",
    "print(\"Cosine Similarity between c2 and d2:\", cosine_similarity_distance(cluster_centroid_2, d2))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d3:\", cosine_similarity_distance(cluster_centroid_1, d3))\n",
    "print(\"Cosine Similarity between c2 and d3:\", cosine_similarity_distance(cluster_centroid_2, d3))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d4:\", cosine_similarity_distance(cluster_centroid_1, d4))\n",
    "print(\"Cosine Similarity between c2 and d4:\", cosine_similarity_distance(cluster_centroid_2, d4))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d5:\", cosine_similarity_distance(cluster_centroid_1, d5))\n",
    "print(\"Cosine Similarity between c2 and d5:\", cosine_similarity_distance(cluster_centroid_2, d5))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d6:\", cosine_similarity_distance(cluster_centroid_1, d6))\n",
    "print(\"Cosine Similarity between c2 and d6:\", cosine_similarity_distance(cluster_centroid_2, d6))\n",
    "\n",
    "print(\"Cosine Similarity between c1 and d7:\", cosine_similarity_distance(cluster_centroid_1, d7))\n",
    "print(\"Cosine Similarity between c2 and d7:\", cosine_similarity_distance(cluster_centroid_2, d7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c052664-7f9d-411d-ad40-e3bca3fc7840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Clusters for K=2:\n",
      "Cluster 1: d1, d3, d4, d5\n",
      "Cluster 2: d6, d2, d7\n",
      "Iterations = 2\n",
      "Total Inertia: 14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Clusters for K=2:\")\n",
    "print(\"Cluster 1: d1, d3, d4, d5\")\n",
    "print(\"Cluster 2: d6, d2, d7\")\n",
    "\n",
    "print (\"Iterations = 2\")\n",
    "\n",
    "# Cluster 1\n",
    "cluster_1 = np.array([d1, d3, d4, d5])\n",
    "cluster_centroid_1 = np.mean(cluster_1, axis=0)\n",
    "inertia_cluster_1 = np.sum(np.linalg.norm(cluster_1 - cluster_centroid_1, axis=1)**2)\n",
    "\n",
    "# Cluster 2\n",
    "cluster_2 = np.array([d6, d2, d7])\n",
    "cluster_centroid_2 = np.mean(cluster_2, axis=0)\n",
    "inertia_cluster_2 = np.sum(np.linalg.norm(cluster_2 - cluster_centroid_2, axis=1)**2)\n",
    "\n",
    "# Total Inertia\n",
    "total_inertia = inertia_cluster_1 + inertia_cluster_2\n",
    "print(\"Total Inertia:\", total_inertia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de86c743-9a56-4dfa-a091-ce8116eddf17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2:\n",
      "Cost (Inertia): 14.0\n",
      "Iterations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prive\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#condensed version of entire calculations process shown initially. \n",
    "# Initialize centroids randomly\n",
    "initial_centroids_k2 = data_points[np.random.choice(data_points.shape[0], size=2, replace=False)]\n",
    "\n",
    "# K-means clustering\n",
    "kmeans_k2 = KMeans(n_clusters=2, init=initial_centroids_k2, n_init=1, random_state=42, algorithm='lloyd', tol=1e-4)\n",
    "kmeans_k2.fit(data_points)\n",
    "\n",
    "# Compute the inertia and the number of iter\n",
    "cost_k2 = kmeans_k2.inertia_\n",
    "iterations_k2 = kmeans_k2.n_iter_\n",
    "\n",
    "print(\"K=2:\")\n",
    "print(\"Cost (Inertia):\", cost_k2)\n",
    "print(\"Iterations:\", iterations_k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "105748b9-6a00-4366-949e-0430986f39ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K=3:\n",
      "Cost (Inertia): 11.0\n",
      "Iterations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prive\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize centroids randomly\n",
    "# Perform an identical process as K=2 but for 3 unique centroids or K=3 \n",
    "initial_centroids_k3 = data_points[np.random.choice(data_points.shape[0], size=3, replace=False)]\n",
    "\n",
    "# K-means clustering\n",
    "kmeans_k3 = KMeans(n_clusters=3, init=initial_centroids_k3, n_init=1, random_state=42, algorithm='lloyd', tol=1e-4)\n",
    "kmeans_k3.fit(data_points)\n",
    "\n",
    "# Compute the inertia and the number of iter\n",
    "cost_k3 = kmeans_k3.inertia_\n",
    "iterations_k3 = kmeans_k3.n_iter_\n",
    "\n",
    "print(\"\\nK=3:\")\n",
    "print(\"Cost (Inertia):\", cost_k3)\n",
    "print(\"Iterations:\", iterations_k3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
